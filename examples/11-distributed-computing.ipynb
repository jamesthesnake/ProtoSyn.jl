{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.1",
   "language": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Welcome to the ProtoSyn.jl examples\n",
    "\n",
    "# 11 - Distributed Computing\n",
    "\n",
    "By being developed in Julia, ProtoSyn enjoys some of the features naturally provided by the language, such as easy SIMD and GPU acceleration, a rich package environment and, among others, access to high level parallel and distributed computing routines. In this example we will take a look on how to launch and gather several decoys of the same Monte Carlo simulation. By having multiple decoys in parallel, given the random nature of the algorithm, we can have a greater confidence in the complete sampling of the conformational space, and that the obtained result is real. In order to do this, we first need to load the Distributed package and define the number of CPU workers (this number should be lower than the number of cores available)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 4;\n",
    "addprocs(n_workers);"
   ]
  },
  {
   "source": [
    "The set-up of the code now needs to be replicated in each worker, using the `@everywhere` macro."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using ProtoSyn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    pose                 = ProtoSyn.Peptides.load(\"data/2a3d.pdb\")\n",
    "    selection            = an\"C\" | an\"N\"\n",
    "    probability_mutation = 1/count(selection(pose))\n",
    "    dihedral_mutator     = ProtoSyn.Mutators.DihedralMutator(randn, probability_mutation, 1.0, selection)\n",
    "    callback             = ProtoSyn.Common.default_energy_step_callback(10)\n",
    "    thermostat           = ProtoSyn.Drivers.get_linear_quench(1.0, 500)\n",
    "    energy_function      = ProtoSyn.Common.default_energy_function()\n",
    "    energy_function.clean_cache_every = 10\n",
    "    \n",
    "    monte_carlo          = ProtoSyn.Drivers.MonteCarlo(energy_function, dihedral_mutator, callback, 500, thermostat)\n",
    "\n",
    "    function start_simulation(job_cards::RemoteChannel, results::RemoteChannel)\n",
    "        while true\n",
    "            println(\"Starting simulation on worker $(myid())\")\n",
    "            job  = take!(job_cards)\n",
    "            pose = ProtoSyn.Peptides.load(\"data/2a3d.pdb\")\n",
    "            monte_carlo(pose)\n",
    "            put!(results, pose)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "source": [
    "Part of the set-up of a distributed code in the `start_simulation` function. This start and infine loop that continuously takes \"job cards\" from a RemoteChannel, performs the job, and returns the result to a results RemoteChannel. The job card can, optionally, contain instructions of extra information. In this case, it's just a measure of how many jobs were requested and are left in the queue. whenever a worker finishes a simulation, if extra jobs are queued up, it starts a new simulation. In order for this strategy to work, we first need to create and populate the jobs queue, as well as create the results RemoteChannel."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "job_queue = RemoteChannel(() -> Channel{Int16}(N))\n",
    "for job_n in 1:N\n",
    "    put!(job_queue, Int16(job_n))\n",
    "end\n",
    "job_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_queue = RemoteChannel(() -> Channel{Any}(N))"
   ]
  },
  {
   "source": [
    "We can now begin spawning the 8 simulations in our 4 workers, by calling the `start_simulation` method in each one of them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in workers()\n",
    "    remote_do(start_simulation, p, job_queue, results_queue)\n",
    "end"
   ]
  },
  {
   "source": [
    "A second infinite loop continously checks the results RemoteChannel in order to retrieve the finished simulation results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "    local n = N\n",
    "    results = []\n",
    "    while n > 0\n",
    "        result = take!(results_queue)\n",
    "        push!(results, result)\n",
    "        n = n - 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}